p. 2

패턴인식??

	-> Cognitive Science > Artificial inteligence > Pattern Recognition
	-> 사람의 인지 > 기계의 생각하는 능력 > 기계의 생각하는 능력 중 패턴인식

	-> 머신 러닝과 반대되는 개념 ? 
		-> Rule based Algorithm


---------------------------------------------------------------------
p. 3

머신러닝의 목적

	-> 컴퓨터가 스스로 숨겨진 공식을 찾게 하는것!
	-> 숨겨진 패턴을 인식하거나, 오차를 최소화 하는 공식을 찾는 등
		-> Classification & Regression
		-> 사물을 구분하고 & 함수를 찾는것

---------------------------------------------------------------------
p. 4

Feature와 Pattern

	-> Feature는 머리카락의 길이, 색상 등의 특징

	-> Pattern은 feature들의 집합 (ex. 여러가지 특징이 모여 남자의 패턴을 갖는다 or 여자의 패턴을 갖는다 등)



---------------------------------------------------------------------
p. 5

강아지와 고양이를 구분한다고 하면

	-> 꼬리의 모양이 좋은 Feature이 될것이고
	-> 발톱의 길이는 나쁜 Feature이 될것이다 (서로 구분이 잘 안되기 때문에)

Pattern은 크게 2가지로 나눌 수 있다

	-> Linear Classifier로 구분되거나 Nonlinear Classifier로 구분되거나



---------------------------------------------------------------------
p. 6

머신러닝의 과정

	-> 1. dataset을 깔끔하게 정리한다
	-> 2. 들어온 데이터들에서 특정 feature를 뽑거나 & feature에 대한 dimension을 줄이거나
	-> 3. 분류, 예측
	-> 4. 평가

---------------------------------------------------------------------
p. 7

데이터를 처리하고 -> 모델을 만들고 -> 모델을 평가한다.



---------------------------------------------------------------------
p. 8

Data Preprocessing

	-> 데이터의 불필요한 노이즈를 없애는 등의 과정을 거쳐야한다

Data Cleaning

	-> 데이터에서 말이 안되는 것들 (ex. 존재할 수 없는 데이터)을 제거해야한다. 

---------------------------------------------------------------------
p. 10

Data Reduction Strategies

	-> 데이터가 너무 많으면 줄일 필요도 있다.
	-> 처리해야할 데이터가 너무 많으면 계산양도 많아지고, 효율적인 모델도 만들 수 없다.
		-> 차원의 저주 : Feature이 무작정 많아진다고 성능이 좋아지지는 않는다.



---------------------------------------------------------------------
p. 11

Curse of Dimensionality

	-> 차원의 저주
	-> Feature이 불필요하게 많다면 오히려 성능을 떨어뜨린다.




---------------------------------------------------------------------
p. 









---------------------------------------------------------------------
p. 









---------------------------------------------------------------------
p. 









---------------------------------------------------------------------
p. 









---------------------------------------------------------------------
p. 









---------------------------------------------------------------------
p. 









---------------------------------------------------------------------
p. 









---------------------------------------------------------------------
p. 









---------------------------------------------------------------------
p. 









---------------------------------------------------------------------
p. 









---------------------------------------------------------------------
p. 









---------------------------------------------------------------------
p. 









---------------------------------------------------------------------
p. 









---------------------------------------------------------------------
p. 









---------------------------------------------------------------------
