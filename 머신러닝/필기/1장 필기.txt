p. 2

패턴인식??

	-> Cognitive Science > Artificial inteligence > Pattern Recognition
	-> 사람의 인지 > 기계의 생각하는 능력 > 기계의 생각하는 능력 중 패턴인식

	-> 머신 러닝과 반대되는 개념 ? 
		-> Rule based Algorithm


---------------------------------------------------------------------
p. 3

머신러닝의 목적

	-> 컴퓨터가 스스로 숨겨진 공식을 찾게 하는것!
	-> 숨겨진 패턴을 인식하거나, 오차를 최소화 하는 공식을 찾는 등
		-> Classification & Regression
		-> 사물을 구분하고 & 함수를 찾는것

---------------------------------------------------------------------
p. 4

Feature와 Pattern

	-> Feature는 머리카락의 길이, 색상 등의 특징

	-> Pattern은 feature들의 집합 (ex. 여러가지 특징이 모여 남자의 패턴을 갖는다 or 여자의 패턴을 갖는다 등)



---------------------------------------------------------------------
p. 5

강아지와 고양이를 구분한다고 하면

	-> 꼬리의 모양이 좋은 Feature이 될것이고
	-> 발톱의 길이는 나쁜 Feature이 될것이다 (서로 구분이 잘 안되기 때문에)

Pattern은 크게 2가지로 나눌 수 있다

	-> Linear Classifier로 구분되거나 Nonlinear Classifier로 구분되거나



---------------------------------------------------------------------
p. 6

머신러닝의 과정

	-> 1. dataset을 깔끔하게 정리한다
	-> 2. 들어온 데이터들에서 특정 feature를 뽑거나 & feature에 대한 dimension을 줄이거나
	-> 3. 분류, 예측
	-> 4. 평가

---------------------------------------------------------------------
p. 7

데이터를 처리하고 -> 모델을 만들고 -> 모델을 평가한다.



---------------------------------------------------------------------
p. 8

Data Preprocessing

	-> 데이터의 불필요한 노이즈를 없애는 등의 과정을 거쳐야한다

Data Cleaning

	-> 데이터에서 말이 안되는 것들 (ex. 존재할 수 없는 데이터)을 제거해야한다. 

---------------------------------------------------------------------
p. 10

Data Reduction Strategies

	-> 데이터가 너무 많으면 줄일 필요도 있다.
	-> 처리해야할 데이터가 너무 많으면 계산양도 많아지고, 효율적인 모델도 만들 수 없다.
		-> 차원의 저주 : Feature이 무작정 많아진다고 성능이 좋아지지는 않는다.



---------------------------------------------------------------------
p. 11

Curse of Dimensionality

	-> 차원의 저주
	-> Feature이 불필요하게 많다면 오히려 성능을 떨어뜨린다.




---------------------------------------------------------------------
p. 12

Data Transformation

	-> 가우시안 분포와 같이 데이터를 노말라이즈 하는등의 변환이 필요하다

분류에는 여러가지가 있다



---------------------------------------------------------------------
p. 15

지도학습, 비지도학습, 강화학습이 있다.

	-> 지도학습 : 답을 알려주고 학습을 시키는것
	-> 비지도학습 : 답을 알려주지 않고 알아서 구분하는것
	-> 강화학습 : 보상을 주고 학습하는것
		-> 답을 찾기보다 성능을 높이기 위함


---------------------------------------------------------------------
p. 17,18

One Variable Linear Regression

	-> Input 변수가 하나인 선형회귀
	-> 하루에 담배를 얼마나 피는지와 수명간의 그래프
	-> input변수는 담배를 얼마나 폈는지에 대한 값 하나이다.

	-> 모델링 : 데이터의 성질을 수식으로 나타내는것
	-> 모든 경우에 대해 오차가 최소화 되는 세타값을 찾아야 한다.


---------------------------------------------------------------------
p. 19

Cost Function

	-> 예측값과 실제값의 차이를 제곱한 후 모두 더한다
	-> 이러한 cost값이 최소화 되는 cost값을 찾아야 한다.
		-> 앞의 1/n은 n개의 데이터에대해 평균을 내려고, 2는 미분할때 계산 편하게 하려고



---------------------------------------------------------------------
p. 20

머리의 길이로 남자와 여자를 구분하는 문제

	-> 이를 Regression으로 어떻게 해결하는가 

	-> 새로운 데이터가 들어왔을때, h(x)함수의 값을 구하고
	-> 이 값이 0.5이상이면 여자 아니면 남자로 classification한다.


---------------------------------------------------------------------
p. 21

Outlier

	-> 만약 어떤 여성의 머리가 너무 길다면?
	-> regression모델의 기울기가 크게 바뀐다
	-> 문제? 이전에는 여성으로 분류되었을 법한 머리길이도
		-> 함수의 기울기가 낮아져서 남성으로 분류될 수 있다.


---------------------------------------------------------------------
p. 22

이런 Outlier를 아예 배제하지는 말고
	-> 이에 대응하기 위해 Sigmoid함수를 써보자

	-> input에 대한 output이 기존의 regression모델보다 더 명확하다!
	-> 더 확실한 classification이 가능하다.



---------------------------------------------------------------------
p. 31

Hubel and Wiesel 실험	

	-> Neural Science의 기폭제가 됨
	-> 이전까지는 뇌의 기능및 현상에 대한 지식이 없었음

	-> 뇌의 어느부분이 어떤 기능을 담당하는가를 찾아냄
	-> 뇌의 Visual System을 기반으로 컴퓨터를 통해 표현한 것이 CNN


---------------------------------------------------------------------
p. 37

Evaluation

	-> 모델을 피드백 하기 위함
	-> 보통 데이터셋을 나눠 training과 validation, test로 씀
		-> 데이터셋을 바꿔 교차검증 필요




---------------------------------------------------------------------
p. 38

Confusion matrix

	-> 반드시 이를 활용해서 평가해야함

	-> ex.) 만약 전투기의 피아를 식별하는 기계가 모든 전투기를 100%아군으로 판단할때
		-> 100중 95대의 아군 전투기를 놓고 측정하면 95%의 정확도를 보여줌
			-> 이것은 잘못되었다!!!
		-> 따라서 아군기와 적군기를 나눠 따로 평가해야함
	 
	-> 일반적으로 recall rate와 precision으로 전체를 평가할 수 있다.



---------------------------------------------------------------------
p. 39

Sensitivity는 recall rate와 같음

보통 두가지 값을 묶어서 평가할때 쓰임





---------------------------------------------------------------------
p. 40

ROC 커브???

	-> 모델을 평가할때 쓰임
	-> 주로 어떤 모델이 더 좋은지 판단하기 위함

	-> 왼쪽 그림의 겹쳐있는 부분이 많을수록 좋지않은 모델
	-> ROC에서는 곡선이 왼쪽 위로 굽어질 수록 좋은 모델



---------------------------------------------------------------------
p. 









---------------------------------------------------------------------
